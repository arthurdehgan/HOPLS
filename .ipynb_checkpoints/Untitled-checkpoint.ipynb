{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition._tucker import partial_tucker\n",
    "from tensorly.tenalg import mode_dot, multi_mode_dot, kronecker\n",
    "import numpy as np\n",
    "from numpy.linalg import svd, pinv\n",
    "\n",
    "\n",
    "def rmsep(y_true, y_pred):\n",
    "    \"\"\"Compute Root Mean Square Error between two arrays.\"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2, axis=0))\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Compute Root Mean Square Percentage Error between two arrays.\"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2, axis=0))\n",
    "\n",
    "\n",
    "def qsquared(y_true, y_pred):\n",
    "    \"\"\"Compute the Q^2 Error between two arrays.\"\"\"\n",
    "    return 1 - ((tl.norm(y_true - y_pred) ** 2) / (tl.norm(y_true) ** 2))\n",
    "\n",
    "\n",
    "def cov(A, B):\n",
    "    \"\"\"Computes the mode 1 (mode 0 in python) contraction of 2 matrices.\"\"\"\n",
    "    assert A.shape[0] == B.shape[0], \"A and B need to have the same shape on axis 0\"\n",
    "    dimension_A = A.shape[1:]\n",
    "    dimension_B = B.shape[1:]\n",
    "    dimensions = list(dimension_A) + list(dimension_B)\n",
    "    rmode_A = len(dimension_A)\n",
    "    dim = A.shape[0]\n",
    "    C = tl.zeros(dimensions)\n",
    "    indices = []\n",
    "    for mode in dimensions:\n",
    "        indices.append(range(mode))\n",
    "    for idx in product(*indices):\n",
    "        idx_A, idx_B = list(idx[:rmode_A]), list(idx[rmode_A:])\n",
    "        C[idx] = np.sum(\n",
    "            [A[tuple([i] + idx_A)] * B[tuple([i] + idx_B)] for i in range(dim)]\n",
    "        )\n",
    "    return C\n",
    "    # alpha = \"bcdefghijklmnopqrstuvwxyz\"\n",
    "    # A_alpha = alpha[: len(A.shape) - 1]\n",
    "    # B_alpha = alpha[1 - len(B.shape) :]\n",
    "    # string = \"a\" + A_alpha + \",\" + B_alpha + \"->\" + A_alpha + B_alpha\n",
    "    # print(A.shape, B.shape)\n",
    "    # return np.einsum(\"a...,a...->...\", A, B)\n",
    "    # return\n",
    "\n",
    "\n",
    "class HOPLS:\n",
    "    def __init__(self, R, Ln, Kn=None, metric=None, epsilon=0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            R: int, The number of latent vectors.\n",
    "\n",
    "            Ln: list, the ranks for the decomposition of X: [L2, ..., LN].\n",
    "\n",
    "            Kn: list, the ranks for the decomposition of Y: [K2, ..., KM].\n",
    "\n",
    "            epsilon: Float, default: 10e-7, The implicit secondary criterion of the\n",
    "                algorithm. The algorithm will stop if we have not reached R but the\n",
    "                residuals have a norm smaller than epsilon.\n",
    "        \"\"\"\n",
    "        self.R = R\n",
    "        self.Ln = Ln\n",
    "        self.Kn = Kn\n",
    "        self.epsilon = epsilon\n",
    "        if metric is None:\n",
    "            self.metric = qsquared\n",
    "        else:\n",
    "            self.metric = metric\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Compute the HOPLS for X and Y wrt the parameters R, Ln and Kn.\n",
    "\n",
    "        Parameters:\n",
    "            X: tensorly Tensor, The target tensor of shape [i1, ... iN], N >= 3.\n",
    "\n",
    "            Y: tensorly Tensor, The target tensor of shape [j1, ... jM], M >= 3.\n",
    "\n",
    "        Returns:\n",
    "            G: Tensor, The core Tensor of the HOPLS for X, of shape (R, L2, ..., LN).\n",
    "\n",
    "            P: List, The N-1 loadings of X. of shape (R, I(n+1), L(n+1)) for n from 1 to N-1.\n",
    "\n",
    "            D: Tensor, The core Tensor of the HOPLS for Y, of shape (R, K2, ..., KN).\n",
    "\n",
    "            Q: List, The N-1 loadings of Y.\n",
    "\n",
    "            ts: Tensor, The latent vectors of the HOPLS, of shape (i1, R).\n",
    "        \"\"\"\n",
    "        # check parameters\n",
    "        X_mode = len(X.shape)\n",
    "        Y_mode = len(Y.shape)\n",
    "        assert Y_mode >= 2, \"Y need to be mode 2 minimum.\"\n",
    "        assert X_mode >= 3, \"X need to be mode 3 minimum.\"\n",
    "        assert (\n",
    "            len(self.Ln) == X_mode - 1\n",
    "        ), f\"The list of ranks for the decomposition of X (Ln) need to be equal to the mode of X -1: {X_mode-1}.\"\n",
    "        if Y_mode == 2:\n",
    "            return self._fit_2d(X, Y)\n",
    "        assert (\n",
    "            len(self.Kn) == Y_mode - 1\n",
    "        ), f\"The list of ranks for the decomposition of Y (Kn) need to be equal to the mode of Y -1: {Y_mode-1}.\"\n",
    "        # Initialization\n",
    "        Er, Fr = X, Y\n",
    "        In = X.shape\n",
    "        P, Q = [], []\n",
    "        G = tl.zeros((self.R, *self.Ln))\n",
    "        D = tl.zeros((self.R, *self.Kn))\n",
    "        T = tl.zeros((In[0], self.R))\n",
    "        # Beginning of the algorithm\n",
    "        for r in range(self.R):\n",
    "            if tl.norm(Er) > self.epsilon and tl.norm(Fr) > self.epsilon:\n",
    "                Cr = cov(Er, Fr)\n",
    "                # HOOI tucker decomposition of C\n",
    "                _, latents = tucker(\n",
    "                    Cr,ranks=self.Ln + self.Kn, n_iter_max=int(1e6), tol=1e-7\n",
    "                )\n",
    "                print(np.shape(latents))\n",
    "                # Getting P and Q\n",
    "                Pr = latents[: len(Er.shape) - 1]\n",
    "                Qr = latents[len(Er.shape) - 1 :]\n",
    "                # computing product of Er by latents of X\n",
    "                tr = multi_mode_dot(Er, Pr, list(range(1, len(Pr))), transpose=True)\n",
    "                # Getting t as the first leading left singular vector of the product\n",
    "                tr = svd(tl.unfold(tr, 0))[0][:, 0]\n",
    "                tr = tr[..., np.newaxis]\n",
    "                # recomposition of the core tensors\n",
    "                Gr = tl.tucker_to_tensor(Er, [tr] + Pr, transpose_factors=True)\n",
    "                Dr = tl.tucker_to_tensor(Fr, [tr] + Qr, transpose_factors=True)\n",
    "                # Deflation\n",
    "                Er = Er - tl.tucker_to_tensor(Gr, [tr] + Pr)\n",
    "                Fr = Fr - tl.tucker_to_tensor(Dr, [tr] + Qr)\n",
    "                # Gathering of\n",
    "                P.append(Pr)\n",
    "                Q.append(Qr)\n",
    "                G[r] = Gr[0]\n",
    "                D[r] = Dr[0]\n",
    "                T[:, r] = tr[:, 0]\n",
    "            else:\n",
    "                break\n",
    "        self.model = (P, Q, G, D, T)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, Y):\n",
    "        \"\"\"Compute the HOPLS for X and Y wrt the parameters R, Ln and Kn.\n",
    "\n",
    "        Parameters:\n",
    "            X: tensorly Tensor, The tensor we wish to do a prediction from.\n",
    "            Of shape [i1, ... iN], N >= 3.\n",
    "\n",
    "            Y: tensorly Tensor, used only for the shape of the prediction.\n",
    "\n",
    "        Returns:\n",
    "            Y_pred: tensorly Tensor, The predicted Y from the model.\n",
    "        \"\"\"\n",
    "        P, Q, G, D, T = self.model\n",
    "        N = len(self.Ln)\n",
    "        M = len(self.Kn)\n",
    "        G_pi = []\n",
    "        if len(Y.shape) == 2:\n",
    "            Q_star = tl.zeros(Q.shape)\n",
    "        else:\n",
    "            Q_star = []\n",
    "        W = tl.zeros((*X.shape[1:], self.R)).reshape(-1, self.R)\n",
    "        for r in range(self.R):\n",
    "            G_pi.append(pinv(G[r]))\n",
    "            W[:, r] = np.matmul(\n",
    "                kronecker([P[r][N - n - 1] for n in range(N)]), G_pi[-1].reshape(-1)\n",
    "            )\n",
    "            if len(Y.shape) > 2:\n",
    "                Q_star.append(\n",
    "                    np.matmul(\n",
    "                        D[r].reshape(-1),\n",
    "                        kronecker([Q[r][M - n - 1] for n in range(M)]).T,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                Q_star[:, r] = D[r, r] * Q[:, r]\n",
    "\n",
    "        if len(Y.shape) > 2:\n",
    "            Q_star = tl.tensor(Q_star).T\n",
    "        return np.matmul(np.matmul(tl.unfold(X, 0), W), Q_star.T).reshape(Y.shape)\n",
    "        # return np.matmul(T, Q_star.T).reshape(Y.shape)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        self.fit(X, Y)\n",
    "        Y_pred = self.predict(X, Y)\n",
    "        return self.metric(Y.reshape(Y.shape[0], -1), Y_pred.reshape(Y.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.tenalg.n_mode_product import mode_dot\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from joblib import Parallel, delayed\n",
    "from hopls import HOPLS, qsquared\n",
    "\n",
    "\n",
    "def hyper_params_search(data, target, metric=None, verbose=True):\n",
    "    old_error = -np.inf\n",
    "    # Just like in the paper, we simplify by having l for all ranks\n",
    "    for R, l in product(range(3, 7), range(3, 10)):\n",
    "        hopls = HOPLS(\n",
    "            R, [l] * (len(data.shape) - 1), [l] * (len(data.shape) - 1), metric=None\n",
    "        )\n",
    "        error = np.mean(hopls.score(data, target))\n",
    "        if error > old_error:\n",
    "            old_error = error\n",
    "            best_params = [R, l, error]\n",
    "    if verbose:\n",
    "        print(\"Best model is with R={} and l={}, error={:.2f}\".format(*best_params))\n",
    "    return best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tl.tensor(np.random.normal(size=(10, 5)))\n",
    "P = tl.tensor(np.random.normal(size=(5, 7, 7)))\n",
    "Q = tl.tensor(np.random.normal(size=(5, 7, 7)))\n",
    "# Q = tl.tensor(np.random.normal(size=(5, 12)))\n",
    "E = tl.tensor(np.random.normal(size=(10, 10, 11)))\n",
    "F = tl.tensor(np.random.normal(size=(10, 10, 10)))\n",
    "X = mode_dot(P, T, 0)\n",
    "Y = mode_dot(Q, T, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (7,7) into shape (8,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-257eeb82b71a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyper_params_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-241-f30f074a1ac3>\u001b[0m in \u001b[0;36mhyper_params_search\u001b[0;34m(data, target, metric, verbose)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         )\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhopls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mold_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mold_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/HOPLS/hopls.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_star\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# return np.matmul(T, Q_star.T).reshape(Y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/HOPLS/hopls.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;31m# Gathering of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (7,7) into shape (8,8)"
     ]
    }
   ],
   "source": [
    "hyper_params_search(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (20, 10, 10) and (10, 3) not aligned in mode-1 multiplication: 10 (mode 1) != 3 (dim 1 of matrix)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-350d579b17e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhyper_params_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# test = PLSRegression(n_components=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-219-f30f074a1ac3>\u001b[0m in \u001b[0;36mhyper_params_search\u001b[0;34m(data, target, metric, verbose)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         )\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhopls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mold_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mold_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/HOPLS/hopls.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/HOPLS/hopls.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    164\u001b[0m         ), f\"The list of ranks for the decomposition of X (Ln) need to be equal to the mode of X -1: {X_mode-1}.\"\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         assert (\n\u001b[1;32m    168\u001b[0m             \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY_mode\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/HOPLS/hopls.py\u001b[0m in \u001b[0;36m_fit_2d\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mPr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_mode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGr_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorly/tenalg/n_mode_product.py\u001b[0m in \u001b[0;36mmulti_mode_dot\u001b[0;34m(tensor, matrix_or_vec_list, modes, skip, transpose)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_or_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdecrement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_or_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdecrement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_or_vec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorly/tenalg/n_mode_product.py\u001b[0m in \u001b[0;36mmode_dot\u001b[0;34m(tensor, matrix_or_vector, mode)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 raise ValueError(\n\u001b[1;32m     40\u001b[0m                     'shapes {0} and {1} not aligned in mode-{2} multiplication: {3} (mode {2}) != {4} (dim 1 of matrix)'.format(\n\u001b[0;32m---> 41\u001b[0;31m                         \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_or_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_or_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                     ))\n\u001b[1;32m     43\u001b[0m             \u001b[0mnew_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_or_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (20, 10, 10) and (10, 3) not aligned in mode-1 multiplication: 10 (mode 1) != 3 (dim 1 of matrix)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the HOPLS for X and Y wrt the parameters R, Ln and Kn.\n",
    "\n",
    "Parameters:\n",
    "    X: tensorly Tensor, The target tensor of shape [i1, ... iN], N >= 3.\n",
    "\n",
    "    Y: tensorly Tensor, The target tensor of shape [j1, ... jM], M >= 3.\n",
    "\n",
    "Returns:\n",
    "    G: Tensor, The core Tensor of the HOPLS for X, of shape (R, L2, ..., LN).\n",
    "\n",
    "    P: List, The N-1 loadings of X. of shape (R, I(n+1), L(n+1)) for n from 1 to N-1.\n",
    "\n",
    "    D: Tensor, The core Tensor of the HOPLS for Y, of shape (R, K2, ..., KN).\n",
    "\n",
    "    Q: List, The N-1 loadings of Y.\n",
    "\n",
    "    ts: Tensor, The latent vectors of the HOPLS, of shape (i1, R).\n",
    "\"\"\"\n",
    "# check parameters\n",
    "X_mode = len(X.shape)\n",
    "Y_mode = len(Y.shape)\n",
    "assert Y_mode >= 2, \"Y need to be mode 2 minimum.\"\n",
    "assert X_mode >= 3, \"X need to be mode 3 minimum.\"\n",
    "assert (\n",
    "    len(Ln) == X_mode - 1\n",
    "), f\"The list of ranks for the decomposition of X (Ln) need to be equal to the mode of X -1: {X_mode-1}.\"\n",
    "if Y_mode == 2:\n",
    "    return self._fit_2d(X, Y, Ln)\n",
    "assert (\n",
    "    len(Kn) == Y_mode - 1\n",
    "), f\"The list of ranks for the decomposition of Y (Ln) need to be equal to the mode of Y -1: {Y_mode-1}.\"\n",
    "# Initialization\n",
    "Er, Fr = X, Y\n",
    "P, Q, G, D, T = [], [], [], [], []\n",
    "# Beginning of the algorithm\n",
    "for i in range(self.R):\n",
    "    if tl.norm(Er) > epsilon and tl.norm(Fr) > epsilon:\n",
    "        Cr = cov(Er, Fr)\n",
    "        # HOOI ticker decomposition of C\n",
    "        _, latents = partial_tucker(Cr, ranks=Ln)\n",
    "        # Getting P and Q\n",
    "        Pr = latents[: len(Er.shape) - 1]\n",
    "        Qr = latents[len(Er.shape) - 1 :]\n",
    "        # computing product of Er by latents of X\n",
    "        tr = Er\n",
    "        for k in range(len(Er.shape) - 1):\n",
    "            tr = mode_dot(tr, Pr[k].T, k + 1)\n",
    "        # Getting t as the first leading left singular vector of the product\n",
    "        tr = svd(tl.unfold(tr, 0))[0][:, 0]\n",
    "        tr = tr[..., np.newaxis]\n",
    "        # recomposition of the core tensors\n",
    "        G.append(tl.tucker_to_tensor(Er, [tr.T] + [pn.T for pn in Pr]))\n",
    "        D.append(tl.tucker_to_tensor(Fr, [tr.T] + [qn.T for qn in Qr]))\n",
    "        # Deflation\n",
    "        Er = Er - tl.tucker_to_tensor(G[i], [tr] + Pr)\n",
    "        Fr = Fr - tl.tucker_to_tensor(D[i], [tr] + Qr)\n",
    "        # Gathering of\n",
    "        P.append(Pr)\n",
    "        Q.append(Qr)\n",
    "        T.append(tr)\n",
    "    else:\n",
    "        break\n",
    "# reshaping the loadings\n",
    "P = tl.tensor(P)\n",
    "Q = tl.tensor(Q)\n",
    "# P = [P[:, i] for i in range(P.shape[1])]\n",
    "# Q = [Q[:, i] for i in range(Q.shape[1])]\n",
    "model = (\n",
    "    tl.tensor(G).squeeze(),\n",
    "    P,\n",
    "    tl.tensor(D).squeeze(),\n",
    "    Q,\n",
    "    tl.tensor(T).squeeze(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core, factors = partial_tucker(tensor, modes=[1, 2], ranks=[4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = np.dot(factors[0],factors[0].T)\n",
    "np.shape(prod)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tl.tensor(np.random.normal(size=(10, 10, 11,13)))*10\n",
    "core, latents = tl.decomposition.tucker(X,rank=11)\n",
    "X_recon = tl.tenalg.multi_mode_dot(core, latents, modes=[0,1,2,3],transpose=False)\n",
    "X_recon2 = tl.tucker_to_tensor(core, latents)\n",
    "print(np.allclose(X_recon, X_recon2))\n",
    "print(np.allclose(X_recon2,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
